{
  "name": "@openlit/ts",
  "version": "1.0.0",
  "homepage": "https://github.com/openlit/openlit#readme",
  "bugs": {
    "url": "https://github.com/openlit/openlit/issues",
    "email": "developer@openlit.io"
  },
  "description": "OpenTelemetry-native Auto instrumentation library for monitoring LLM Applications, facilitating the integration of observability into your GenAI-driven projects",
  "main": "src/index.ts",
  "scripts": {
    "prepare": "npm run build",
    "build": "tsc"
  },
  "keywords": [
    "OpenTelemetry",
    "otel",
    "otlp",
    "llm",
    "tracing",
    "openai",
    "anthropic",
    "claude",
    "cohere",
    "llm monitoring",
    "observability",
    "monitoring",
    "gpt",
    "Generative AI",
    "chatGPT"
  ],
  "author": "openlit",
  "license": "ISC",
  "devDependencies": {
    "@eslint/js": "^9.2.0",
    "eslint": "^8.57.0",
    "eslint-config-prettier": "^9.1.0",
    "eslint-plugin-prettier": "^5.1.3",
    "globals": "^15.1.0",
    "prettier": "^3.2.5",
    "typescript": "^5.4.5",
    "typescript-eslint": "^7.8.0"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.25.0",
    "@opentelemetry/api": "^1.8.0",
    "@opentelemetry/auto-instrumentations-node": "^0.46.1",
    "@opentelemetry/exporter-jaeger": "^1.24.1",
    "@opentelemetry/exporter-otlp-http": "^0.26.0",
    "@opentelemetry/instrumentation": "^0.51.1",
    "@opentelemetry/resources": "^1.24.1",
    "@opentelemetry/sdk-metrics": "^1.24.1",
    "@opentelemetry/sdk-trace-base": "^1.24.1",
    "@opentelemetry/sdk-trace-node": "^1.24.1",
    "@opentelemetry/semantic-conventions": "^1.24.1",
    "js-tiktoken": "^1.0.12",
    "openai": "^4.47.1",
    "tiktoken": "^1.0.15"
  }
}
