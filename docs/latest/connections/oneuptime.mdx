---
title: 'OneUptime'
description: 'LLM Observability with OneUptime and OpenLIT'
---

<Frame>
  <img src="/images/oneuptime-dashboard-1.png" />
  <img src="/images/oneuptime-dashboard-2.png" />
</Frame>

To directly send OpenTelemetry metrics and traces generated by OpenLIT SDK from your AI Application to OneUptime, Follow the below steps.
<Steps>
  <Step title="Get your OneUptime OpenTelemetry Credentials">
    <Steps>
      1. Sign in to your OneUptime account.
      2. Click on `More` in the Navigation bar and click on `Project Settings`.
      3. On the Telemetry Ingestion Key page, click on `Create Ingestion Key` to create a token. 
        ![](https://oneuptime.com/docs/static/images/TelemetryIngestionKeys.png)
      4. Once you created a token, click on `View` to view and copy the token.
        ![](https://oneuptime.com/docs/static/images/TelemetryIngestionKeyView.png)
    </Steps>
  </Step>
  <Step title="Add the following two lines to your application code:">
    <Tabs>
      <Tab title="Setup using function arguments">
      ```python
      import openlit

      openlit.init(
        otlp_endpoint="https://otlp.oneuptime.com", 
        otlp_headers="x-oneuptime-token=YOUR_ONEUPTIME_SERVICE_TOKEN"
      )
      ```

      Replace:
      1. `YOUR_ONEUPTIME_SERVICE_TOKEN` with the OneUptime Ingestion Key value you copied in Step 1. 

      </Tab>
      <Tab title="Setup using Environment Variables">
      ```python
      import openlit

      openlit.init()
      ```

      Run the following command to configure the OTEL endpoint and headers to send metrics and traces to OneUptime:
      ```shell
      export OTEL_EXPORTER_OTLP_ENDPOINT = "https://otlp.oneuptime.com"
      export OTEL_EXPORTER_OTLP_HEADERS = "x-oneuptime-token=YOUR_ONEUPTIME_SERVICE_TOKEN"
      ```

      Replace:
      1. `YOUR_ONEUPTIME_SERVICE_TOKEN` with the OneUptime Ingestion Key` value you copied in Step 1. 
      </Tab>
    </Tabs>
  Refer to the OpenLIT [Python SDK repository](https://github.com/openlit/openlit/tree/main/sdk/python) for more advanced configurations and use cases.
  </Step>
  <Step title="Visualize in OneUptime">
  Once your LLM application is instrumented, you should see the traces and metrics in the OneUptime telemetry traces page.
  </Step>
</Steps>


---

<CardGroup cols={2}>
<Card title="Integrations" href="/latest/integrations/introduction" icon='circle-nodes'>
Start Monitoring your LLM Application 
</Card>
</CardGroup>

  