---
title: 'HyperDX'
description: 'LLM Observability with HyperDX using OpenLIT'
---

<Frame>
  <img src="/images/hyperdx-dashboard-1.png" />
  <img src="/images/hyperdx-dashboard-2.png" />
</Frame>

<Frame>
  <img src="/images/hyperdx-dashboard-3.png" />
</Frame>
To send OpenTelemetry metrics and traces generated by OpenLIT from your LLM Application to HyperDX, Follow the below steps.

<Steps>
  <Step title="Install OpenTelemetry Collector (Optional)">
    This step is optional if you have the OpenTelemetry Collector already running.

    For detailed installation instructions for the OpenTelemetry Collector , please refer to the [OpenTelemetry Collector Documentation](https://opentelemetry.io/docs/collector/installation/). This guide provides comprehensive steps to get you up and running with the Collector on various platforms.
  </Step>
  <Step title="Configure the OpenTelemetry Collector">

    1. **Configure HTTP Receiver**: In the `receivers` section of your OpenTelemetry Collector config, ensure the `http` receiver is set with `endpoint: 0.0.0.0:4318`.
        ```yaml
        receivers:
          otlp:
            protocols:
              http:
                endpoint: 0.0.0.0:4318
        ```

    2. **Define Exporters**: Add `otlp` exporter to export metrics and traces to HyperDX.
        ```yaml
        exporters:
          # HTTP setup
          otlphttp/hdx:
            endpoint: 'https://in-otel.hyperdx.io'
            headers:
            authorization: YOUR_HYPERDX_API_KEY_HERE
            compression: gzip

          # gRPC setup (alternative)
          otlp/hdx:
            endpoint: 'in-otel.hyperdx.io:4317'
            headers:
            authorization: YOUR_HYPERDX_API_KEY_HERE
            compression: gzip
        ```
        Replace:
        1. `YOUR_HYPERDX_API_KEY_HERE` with the your HyperDX API Key. 
            * Example - `x6xx7265-43x3-476x-1112-x9x52x29xxxx`

    3. **Assign Exporters to Pipelines**: Link `otlphttp/hdx` to `service.pipelines.traces` and `service.pipelines.metrics` for data export.
        ```yaml
        service:
          pipelines:
            traces:
              receivers: [ otlp ]
              exporters: [ otlphttp/hdx ]
            metrics:
              receivers: [ otlp ]
              exporters: [ otlphttp/hdx ]
        ```
    
    **Complete Configuration Example**
    <Accordion title="Example Configuration">
    ```yaml
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318

    processors:
      batch:
      memory_limiter:
        # 80% of maximum memory up to 2G
        limit_mib: 1500
        # 25% of limit up to 2G
        spike_limit_mib: 512
        check_interval: 5s

    exporters:
      otlphttp/hdx:
        endpoint: 'https://in-otel.hyperdx.io'
        headers:
        authorization: YOUR_HYPERDX_API_KEY_HERE
        compression: gzip

    service:
      pipelines:
        traces:
          receivers: [ otlp ]
          processors: [ memory_limiter, batch ]
          exporters: [ otlphttp/hdx ]
        metrics:
          receivers: [ otlp ]
          processors: [ memory_limiter, batch ]
          exporters: [ otlphttp/hdx ]
    ```
    </Accordion>

  </Step>
  <Step title="Add the following two lines to your application code:">
    <Tabs>
      <Tab title="Setup using function arguments">
      ```python
      import openlit

      openlit.init(
        otlp_endpoint="YOUR_OTELCOL_URL:4318", 
      )
      ```

      Replace:
      1. `YOUR_OTELCOL_URL:4318` with the URL HTTP endpoint of your OpenTelemetry Collector. 
         * Example - `http://127.0.0.1:4318`
      
      </Tab>
      <Tab title="Setup using Environment Variables">
      ```python
      import openlit

      openlit.init()
      ```

      Run the following command to configure the OTEL endpoint and headers to send metrics and traces to Grafana Cloud:
      ```shell
      export OTEL_EXPORTER_OTLP_ENDPOINT = "YOUR_OTELCOL_URL:4318"
      ```

      Replace:
      1. `YOUR_OTELCOL_URL:4318` with the URL HTTP endpoint of your OpenTelemetry Collector. 
        * Example - `http://127.0.0.1:4318`
      </Tab>
    </Tabs>
  Refer to the OpenLIT [Python SDK repository](https://github.com/openlit/openlit/tree/main/sdk/python) for more advanced configurations and use cases.
  </Step>
  <Step title="Start monitoring using a pre-built HyperDX dashboard">
  1. Log into your HyperDX Instance. HyperDX currently only supports importing dashboards via Terraform.
  1. Run the below Terraform input command to import the dashboard.
    
     ```
     terraform import restapi_object.dashboard_genai_observability /api/v1/dashboards/66bf2320c40e3a520add6e03
     ```
  1. Copy the Terraform Configuration provided in the accordion named [`Terraform Configuration`](#terraform-configuration) below.
  <Note>Make sure to replace `YOUR_HYPERDX_API_KEY_HERE` with your own HyperDX API Key</Note>
  1. Run your Terraform files and you should have the dashboard in your HyperDX instance. 
  <Accordion title="Terraform Configuration">
      ```terraform
      terraform {
        required_providers {
            restapi = {
            source = "Mastercard/restapi"
            version = "1.18.2"
            }
        }
        }

        provider "restapi" {
        uri                  = "https://api.hyperdx.io"
        write_returns_object = true
        debug                = true
        id_attribute         = "data/id"

        headers = {
            "Authorization" = "Bearer YOUR_HYPERDX_API_KEY_HERE", # Your HyperDX API Key here
            "Content-Type" = "application/json"
        }
        }

        locals {
            chart_total_genai_requests_id = "bsprr"
            chart_total_vectordb_requests_id = "f2pi2"
            chart_avg_usage_cost_id = "owhmy"
            chart_total_usage_tokens_id = "670j"
            chart_avg_request_duration_id = "1dja8w"
            chart_top_genai_models_by_usage_id = "1ch83z"
            chart_genai_requests_by_platfom_id = "1jcxpe"
            chart_genai_requests_by_system_id = "r6xow"
            chart_genai_requests_by_environment_id = "6rdog"
            chart_genai_requests_by_application_id = "gln0a"
            chart_average_token_consumption_vs_average_cost__id = "14bopp"
            chart_genai_requests_id = "1jqc2e"
            chart__id = "l2psc"
        }

        resource "restapi_object" "dashboard_genai_observability" {
        path = "/api/v1/dashboards"
        data = jsonencode({
            "name": "GenAI Observability",
            "query": "",
            "tags": ["GenAI"],

            "charts": [{
            "id": local.chart_total_genai_requests_id,
            "name": "Total GenAI Requests",
            "x": 0,
            "y": 2,
            "w": 3,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "number",
                "dataSource": "metrics",
                "groupBy": [],
                "where": "telemetry.sdk.name:\"openlit\"",
                "field": "gen_ai.total.requests - Sum",
                "aggFn": "sum_rate"
                }
            ]
            },
            {
            "id": local.chart_total_vectordb_requests_id,
            "name": "Total VectorDB Requests",
            "x": 3,
            "y": 2,
            "w": 3,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "number",
                "dataSource": "metrics",
                "groupBy": [],
                "where": "telemetry.sdk.name:\"openlit\"",
                "field": "db.total.requests - Sum",
                "aggFn": "sum_rate"
                }
            ]
            },
            {
            "id": local.chart_avg_usage_cost_id,
            "name": "Avg Usage Cost",
            "x": 9,
            "y": 2,
            "w": 3,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "number",
                "dataSource": "metrics",
                "numberFormat": {
                    "factor": 1,
                    "output": "currency",
                    "mantissa": 2,
                    "thousandSeparated": true,
                    "average": false,
                    "decimalBytes": false,
                    "currencySymbol": ""
                },
                "groupBy": [],
                "where": "telemetry.sdk.name:\"openlit\"",
                "field": "gen_ai.usage.cost_bucket - Histogram",
                "aggFn": "p50"
                }
            ]
            },
            {
            "id": local.chart_total_usage_tokens_id,
            "name": "Total Usage Tokens",
            "x": 6,
            "y": 2,
            "w": 3,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "number",
                "dataSource": "metrics",
                "groupBy": [],
                "where": "telemetry.sdk.name:\"openlit\"",
                "field": "gen_ai.usage.total_tokens - Sum",
                "aggFn": "sum_rate"
                }
            ]
            },
            {
            "id": local.chart_avg_request_duration_id,
            "name": "Avg Request Duration",
            "x": 0,
            "y": 4,
            "w": 12,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "time",
                "dataSource": "events",
                "groupBy": [
                    "gen_ai.environment",
                    "gen_ai.application_name"
                ],
                "where": "",
                "field": "duration",
                "aggFn": "avg"
                }
            ]
            },
            {
            "id": local.chart_top_genai_models_by_usage_id,
            "name": "Top GenAI Models by Usage",
            "x": 0,
            "y": 6,
            "w": 4,
            "h": 4,
            "asRatio": false,
            "series": [
                {
                "type": "table",
                "dataSource": "events",
                "groupBy": [
                    "gen_ai.request.model"
                ],
                "where": "",
                "aggFn": "count"
                }
            ]
            },
            {
            "id": local.chart_genai_requests_by_platfom_id,
            "name": "GenAI Requests by Platfom",
            "x": 4,
            "y": 6,
            "w": 4,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "table",
                "dataSource": "events",
                "groupBy": [
                    "gen_ai.system"
                ],
                "where": "",
                "aggFn": "count"
                }
            ]
            },
            {
            "id": local.chart_genai_requests_by_system_id,
            "name": "GenAI Requests by System",
            "x": 8,
            "y": 6,
            "w": 4,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "table",
                "dataSource": "events",
                "groupBy": [
                    "gen_ai.operation.name"
                ],
                "where": "",
                "aggFn": "count"
                }
            ]
            },
            {
            "id": local.chart_genai_requests_by_environment_id,
            "name": "GenAI Requests by Environment",
            "x": 4,
            "y": 8,
            "w": 4,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "table",
                "dataSource": "events",
                "groupBy": [
                    "gen_ai.environment"
                ],
                "where": "",
                "aggFn": "count"
                }
            ]
            },
            {
            "id": local.chart_genai_requests_by_application_id,
            "name": "GenAI Requests by Application",
            "x": 8,
            "y": 8,
            "w": 4,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "table",
                "dataSource": "events",
                "groupBy": [
                    "gen_ai.application_name"
                ],
                "where": "",
                "aggFn": "count"
                }
            ]
            },
            {
            "id": local.chart_average_token_consumption_vs_average_cost__id,
            "name": "Average Token Consumption vs Average Cost ",
            "x": 0,
            "y": 10,
            "w": 12,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "time",
                "dataSource": "events",
                "groupBy": [],
                "where": "telemetry.sdk.name:openlit",
                "field": "gen_ai.usage.input_tokens",
                "aggFn": "avg"
                },
                {
                "type": "time",
                "dataSource": "events",
                "groupBy": [],
                "where": "telemetry.sdk.name:openlit",
                "field": "gen_ai.usage.output_tokens",
                "aggFn": "avg"
                },
                {
                "type": "time",
                "dataSource": "events",
                "groupBy": [],
                "where": "telemetry.sdk.name:openlit",
                "field": "gen_ai.usage.cost",
                "aggFn": "avg"
                }
            ]
            },
            {
            "id": local.chart_genai_requests_id,
            "name": "GenAI Requests",
            "x": 0,
            "y": 12,
            "w": 12,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "search",
                "groupBy": [],
                "where": "telemetry.sdk.name:openlit",
                "aggFn": "count"
                }
            ]
            },
            {
            "id": local.chart__id,
            "name": "",
            "x": 0,
            "y": 0,
            "w": 12,
            "h": 2,
            "asRatio": false,
            "series": [
                {
                "type": "markdown",
                "groupBy": [],
                "where": "",
                "content": "# GenAI Observability\nThis dashboard displays the usage stats of LLMs, Vector Databases and GPUs, tracking OpenTelemetry Traces and Metrics sent using [OpenLIT](https://github.com/openlit/openlit)",
                "aggFn": "count"
                }
            ]
            }]
        })
        }
      ```
  </Accordion>

  </Step>
</Steps>


---

<CardGroup cols={2}>
<Card title="Integrations" href="/latest/integrations/introduction" icon='circle-nodes'>
Start Monitoring your LLM Application 
</Card>
</CardGroup>