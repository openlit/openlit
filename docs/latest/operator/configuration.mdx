---
title: 'Configuration'
description: 'Configure AutoInstrumentation for your applications'
icon: 'gear'
---

Configure zero-code AI observability using AutoInstrumentation Custom Resources. This page covers all configuration options, validation rules, and best practices.

## üìã AutoInstrumentation Overview

The `AutoInstrumentation` Custom Resource defines how the operator should instrument your applications. Each resource specifies:

- **Which pods** to instrument (via selectors)
- **How to instrument** them (provider, version, packages)
- **Where to send** telemetry data (OTLP endpoint)
- **What attributes** to include (environment, service info)

## üéØ Basic Configuration

### Minimal Example

```yaml
apiVersion: openlit.io/v1alpha1
kind: AutoInstrumentation
metadata:
  name: simple-instrumentation
  namespace: default
spec:
  selector:
    matchLabels:
      openlit.io/instrument: "true"
  otlp:
    endpoint: "http://openlit:4318"
```

This minimal configuration:
- Instruments pods with the label `openlit.io/instrument: "true"`
- Uses OpenLIT provider (default)
- Sends telemetry to the specified OTLP endpoint

### Complete Example

```yaml
apiVersion: openlit.io/v1alpha1
kind: AutoInstrumentation
metadata:
  name: comprehensive-instrumentation
  namespace: production
  labels:
    environment: production
    team: ai-platform
spec:
  # Pod selection criteria
  selector:
    matchLabels:
      openlit.io/instrument: "true"
      app.type: "ai-application"
    matchExpressions:
    - key: "environment"
      operator: In
      values: ["production", "staging"]
  
  # Pods to ignore even if they match selector
  ignore:
    matchLabels:
      openlit.io/skip: "true"
  
  # Python instrumentation configuration
  python:
    instrumentation:
      enabled: true
      provider: "openlit"
      version: "latest"
      imagePullPolicy: "IfNotPresent"
      customPackages: "langchain>=0.1.0,chromadb>=0.4.0"
      env:
      - name: OPENLIT_API_KEY
        valueFrom:
          secretKeyRef:
            name: openlit-secret
            key: api-key
  
  # OTLP configuration
  otlp:
    endpoint: "http://openlit:4318"
    headers: "authorization=Bearer token123"
    timeout: 30
  
  # Resource attributes
  resource:
    environment: "production"
    serviceName: "ai-chat-service"
    serviceNamespace: "ai-platform"
```

## üéØ Pod Selection

### Label Selectors

Use `matchLabels` for exact label matching:

```yaml
selector:
  matchLabels:
    openlit.io/instrument: "true"
    app: "chatbot"
    version: "v2"
```

### Expression Selectors

Use `matchExpressions` for advanced matching:

```yaml
selector:
  matchExpressions:
  - key: "environment"
    operator: In
    values: ["production", "staging"]
  - key: "ai-framework"
    operator: Exists
  - key: "legacy-app"
    operator: DoesNotExist
```

**Supported operators:**
- `In`: Label value must be in the list
- `NotIn`: Label value must not be in the list  
- `Exists`: Label key must exist (any value)
- `DoesNotExist`: Label key must not exist

### Ignore Rules

Exclude specific pods even if they match the selector:

```yaml
ignore:
  matchLabels:
    openlit.io/skip: "true"
    system-component: "true"
  matchExpressions:
  - key: "debug-mode"
    operator: Exists
```

## üêç Python Instrumentation

### Provider Configuration

Choose your instrumentation provider:

```yaml
python:
  instrumentation:
    provider: "openlit"  # Options: openlit, openinference, openllmetry, custom
    version: "latest"    # Or specific version like "1.0.0"
    enabled: true        # Enable/disable instrumentation
```

**Available Providers:**
- **`openlit`**: Full-featured OpenLIT instrumentation
- **`openinference`**: OpenInference standard instrumentation  
- **`openllmetry`**: OpenLLMetry instrumentation
- **`custom`**: Custom instrumentation image

### Custom Packages

Install additional Python packages during instrumentation:

```yaml
python:
  instrumentation:
    customPackages: "langchain>=0.1.0,chromadb>=0.4.0,numpy==1.21.0"
```

**Package format:**
- Comma-separated list
- Supports version constraints (`>=`, `==`, `~=`, etc.)
- Standard pip package specifications

### Custom Init Image

Use a custom instrumentation image:

```yaml
python:
  instrumentation:
    provider: "custom"
    customInitImage: "my-registry.com/custom-openlit:v1.0.0"
    imagePullPolicy: "Always"
```

### Environment Variables

Inject environment variables into instrumented containers:

```yaml
python:
  instrumentation:
    env:
    # Direct value
    - name: OPENLIT_DEBUG
      value: "true"
    
    # From secret
    - name: OPENLIT_API_KEY
      valueFrom:
        secretKeyRef:
          name: openlit-secret
          key: api-key
    
    # From configmap
    - name: OPENLIT_CONFIG
      valueFrom:
        configMapKeyRef:
          name: openlit-config
          key: config.yaml
    
    # From field reference
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
```

## üåê OTLP Configuration

### Basic OTLP Setup

```yaml
otlp:
  endpoint: "http://openlit:4318"
  timeout: 30
```

### OTLP with Headers

Include authentication or custom headers:

```yaml
otlp:
  endpoint: "https://otlp.example.com:4318"
  headers: "authorization=Bearer token123,x-api-key=secret456"
  timeout: 60
```

**Header format:**
- Comma-separated key=value pairs
- URL encoding for special characters
- Support for authentication tokens

### OTLP Endpoints

**Common endpoint patterns:**
```yaml
# Local OpenLIT instance
endpoint: "http://openlit:4318"

# OpenTelemetry Collector
endpoint: "http://otel-collector:4318"

# External service with TLS
endpoint: "https://traces.example.com:4318"

# Service mesh internal communication
endpoint: "http://openlit.openlit.svc.cluster.local:4318"
```

## üè∑Ô∏è Resource Attributes

### Standard Attributes

Configure common resource attributes:

```yaml
resource:
  environment: "production"        # deployment.environment
  serviceName: "ai-chat-service"   # service.name override
  serviceNamespace: "ai-platform"  # service.namespace
```

### Automatic Attributes

The operator automatically sets:
- `service.name`: From pod/deployment name
- `service.namespace`: From Kubernetes namespace
- `k8s.pod.name`: Pod name
- `k8s.namespace.name`: Namespace name
- `k8s.deployment.name`: Deployment name (if applicable)

## üîç Status and Validation

### Resource Status

AutoInstrumentation resources report their status:

```yaml
status:
  conditions:
  - type: "Ready"
    status: "True"
    reason: "ValidationSucceeded"
    message: "AutoInstrumentation is ready"
    lastTransitionTime: "2024-01-15T10:30:00Z"
  observedGeneration: 1
  phase: "Ready"
```

**Status phases:**
- `Pending`: Resource is being processed
- `Ready`: Configuration is valid and active
- `Error`: Configuration has validation errors

### Validation Rules

The operator validates configurations:

<AccordionGroup>
  <Accordion title="OTLP Endpoint Validation">
    ```yaml
    # ‚úÖ Valid endpoints
    endpoint: "http://openlit:4318"
    endpoint: "https://traces.example.com:4318"
    
    # ‚ùå Invalid endpoints
    endpoint: ""                    # Empty endpoint
    endpoint: "invalid-url"         # Invalid URL format
    endpoint: "ftp://invalid:123"   # Unsupported protocol
    ```
  </Accordion>
  
  <Accordion title="Timeout Validation">
    ```yaml
    # ‚úÖ Valid timeouts
    timeout: 30
    timeout: 60
    
    # ‚ùå Invalid timeouts
    timeout: 0     # Must be > 0
    timeout: 301   # Must be <= 300
    timeout: -5    # Must be positive
    ```
  </Accordion>
  
  <Accordion title="Provider Validation">
    ```yaml
    # ‚úÖ Valid providers
    provider: "openlit"
    provider: "openinference"
    provider: "openllmetry"
    provider: "custom"
    
    # ‚ùå Invalid providers
    provider: "unknown"    # Unsupported provider
    provider: ""           # Empty provider
    ```
  </Accordion>
</AccordionGroup>

## üé® Configuration Patterns

### Multi-Environment Setup

```yaml
# Production environment
apiVersion: openlit.io/v1alpha1
kind: AutoInstrumentation
metadata:
  name: production-instrumentation
  namespace: production
spec:
  selector:
    matchLabels:
      environment: "production"
  otlp:
    endpoint: "https://prod-traces.company.com:4318"
    headers: "authorization=Bearer prod-token"
  resource:
    environment: "production"

---
# Staging environment  
apiVersion: openlit.io/v1alpha1
kind: AutoInstrumentation
metadata:
  name: staging-instrumentation
  namespace: staging
spec:
  selector:
    matchLabels:
      environment: "staging"
  otlp:
    endpoint: "http://staging-openlit:4318"
  resource:
    environment: "staging"
```

### Framework-Specific Configuration

```yaml
# LangChain applications
apiVersion: openlit.io/v1alpha1
kind: AutoInstrumentation
metadata:
  name: langchain-instrumentation
spec:
  selector:
    matchLabels:
      ai-framework: "langchain"
  python:
    instrumentation:
      provider: "openlit"
      customPackages: "langchain>=0.1.0,langchain-community>=0.0.20"
  otlp:
    endpoint: "http://openlit:4318"

---
# LlamaIndex applications
apiVersion: openlit.io/v1alpha1
kind: AutoInstrumentation
metadata:
  name: llamaindex-instrumentation
spec:
  selector:
    matchLabels:
      ai-framework: "llamaindex"
  python:
    instrumentation:
      provider: "openlit"
      customPackages: "llama-index>=0.9.0"
  otlp:
    endpoint: "http://openlit:4318"
```

### Team-Based Configuration

```yaml
# Data Science team
apiVersion: openlit.io/v1alpha1
kind: AutoInstrumentation
metadata:
  name: datascience-instrumentation
  namespace: datascience
spec:
  selector:
    matchLabels:
      team: "datascience"
  python:
    instrumentation:
      customPackages: "pandas>=1.5.0,numpy>=1.21.0,scikit-learn>=1.0.0"
  resource:
    serviceNamespace: "datascience"

---
# AI Platform team
apiVersion: openlit.io/v1alpha1
kind: AutoInstrumentation
metadata:
  name: ai-platform-instrumentation
  namespace: ai-platform
spec:
  selector:
    matchLabels:
      team: "ai-platform"
  python:
    instrumentation:
      customPackages: "openai>=1.0.0,anthropic>=0.8.0"
  resource:
    serviceNamespace: "ai-platform"
```

## üîÑ Best Practices

### Naming Conventions

```yaml
# ‚úÖ Good naming
metadata:
  name: production-chatbot-instrumentation
  name: staging-langchain-apps
  name: team-datascience-models

# ‚ùå Avoid generic names
metadata:
  name: instrumentation
  name: config
  name: default
```

### Label Strategy

```yaml
# ‚úÖ Recommended labels for pods
labels:
  openlit.io/instrument: "true"  # Primary selector
  app: "chatbot"                 # Application name
  version: "v1.2.0"              # Version tracking
  team: "ai-platform"            # Team ownership
  environment: "production"      # Environment
  ai-framework: "langchain"      # Framework used

# ‚úÖ Recommended ignore labels
labels:
  openlit.io/skip: "true"        # Skip instrumentation
  system-component: "true"       # System pods
  debug-mode: "enabled"          # Debug/test pods
```

### Resource Management

```yaml
# Namespace-scoped resources
metadata:
  namespace: production  # Same namespace as target pods

# Resource limits for init containers
python:
  instrumentation:
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "200m"
        memory: "256Mi"
```

## üìñ Next Steps

<CardGroup cols={2}>
  <Card title="üìñ Usage Examples" href="/latest/operator/usage" icon="code">
    See practical examples and patterns
  </Card>
  <Card title="üîß Troubleshooting" href="/latest/operator/troubleshooting" icon="wrench">
    Debug configuration issues
  </Card>
  <Card title="üîí Security" href="/latest/operator/security" icon="shield-check">
    Security best practices
  </Card>
  <Card title="üìö API Reference" href="/latest/operator/api-reference" icon="book">
    Complete API documentation
  </Card>
</CardGroup>
